## %######################################################%##
#                                                          #
####             This scripts performs the              ####
####           first clistering of hits into            ####
####        "communities" according to criteron         ####
####              1 of the study's method               ####
#                                                          #
## %######################################################%##

# This scripts is lauchned from 9-hitClusteringRound1.R and uses files generated by that script


source("HTvFunctions.R")
library(igraph)

# the first argument is the number of CPUs to use
args <- commandArgs(trailingOnly = TRUE)

# job integer identifier(s) that specifies which super family of TE to process
# these may be separated by comas
job <- as.integer(unlist(strsplit(args[1], ","))) 
nCPUs <- as.integer(args[2])

print(paste("job:", job))

# STEP ONE, we determine which hits to cluster according to the job identifier

# imports the the list of tables of hits (with conversion of copy names to integers)
hitList <- readRDS("TEs/clustering/round1/hitsForFirstClusteringKs05occ200.RDS")

# and the table we generated to indicate which hits to process
batches <- fread("TEs/clustering/round1/batchesKs05occ200.txt")

# the superfamily(ies) to process in this batch
superF <- batches[batch %in% job, superF]
superFam <- splitToColumns(names(hitList), "_", 1)

# selects the groups of hits to cluster for the corresponding super family(ies)
groups <- names(hitList)[superFam %in% superF]



# STEP TWO,import the corresponding self-blast hits of copies within clades ----------------------------------------------------------------
blastFiles <- stri_c("TEs/clustering/selectedHits/", superF, ".out")
blastFiles <- blastFiles[file.exists(blastFiles)]
blastFiles <- blastFiles[file.size(blastFiles) > 0]
blast <- rbindlist(lapply(X = blastFiles, FUN = function(file) {
    fread(
        input = file,
        header = F,
        drop = 4, # we do not need this column from the blast output (hsp length)
        col.names = c("query", "subject", "pID"),

        sep = "\t"
    )
}))
# we convert pIDs to integer as we did for the htt hits (for memory and speed)
blast[, pID := as.integer(pID * 1000L)]



# STEP THREE, clustering of according to "criterion 1" --------------------------------------------------------------------------------
# this function does the clustering per 'group' (hits of pair of clades in a super family)
hitCommunities <- function(group) {

    # we first retreives the hits to cluster. We copy the data table to
    # avoid some side effect related to how data.table functions work
    hits <- copy(hitList[[group]])

    # we obtain the different copies (integer ids) in these hits
    ucopies <- hits[, sort(unique(c(query, subject)))]

    # we convert these to smaller integers so that we can make matrices of blast pID
    # between copies, where a copy id will be a row/column index in the matrix
    hits[, c("qid", "sid") := .(
        match(query, ucopies),
        match(subject, ucopies)
    )]

    # we thus need to use the same ids for the copies in the blast output
    blast[, c("qid", "sid") := .(
        match(hit1, ucopies),
        match(hit2, ucopies)
    )]

    # we extract the hits involving these copies
    selectedHits <- blast[!is.na(qid) & !is.na(sid)]

    # we make a matrix of pID for each copy pair (with pID zero by default, when there is no hit)
    pIDmatrix <- matrix(0L, length(ucopies), length(ucopies))

    # the diagonal is set to 100% pID (*1000), to represent perfect pID for a copy with itself
    diag(pIDmatrix) <- 100000L

    # we fill the matrix, (both semi matrices)
    pIDmatrix[cbind(selectedHits$qid, selectedHits$sid)] <- selectedHits$pID
    pIDmatrix[cbind(selectedHits$sid, selectedHits$qid)] <- selectedHits$pID

    # we cannot always cluster all the hits at once due to the max size of vectors in R (and RAM required)
    # so we get the number of hits to cluster
    nHits <- nrow(hits)

    # and determine the number of batches of hits, since we will have to make all possible pairs of hits
    nBatches <- ceiling(nHits^2 / 2^28)

    # in the following, a hit corresponds to a row index in the "hits" table
    # we split the hits into several batches (1 batch by default)
    hitBatches <- list(1:(nHits - 1L))
    if (nBatches > 1) {
        hitBatches <- splitEqual(hitBatches[[1]], n = nBatches)
    }

    # we "connect" hits 2 by 2 according to criterion 1, with this function:
    criterion_1 <- function(batch) {

        # for a batch of hits, we make all possible pairs of hits.
        # The left-hand hit (hit1) is from the batch, and the right-hand
        # hit (hit2) includes all other hits (including other batches)
        # this ensures that, over all batches, all possible pairs will be made
        pairs <- data.table(
            hit1 = rep(batch, nHits - batch),
            hit2 = unlist(x = lapply(
                X = batch[1]:max(batch) + 1L,
                FUN = function(hit) hit:nHits
            ))
        )

        # we retreive the ids of copies involved in the 2 hits (2 per clade)
        pairs[, c("q1", "s1", "q2", "s2") := data.table(
            hits[hit1, .(qid, sid)],
            hits[hit2, .(qid, sid)]
        )]

        # and retreive the blast pIDs (percentage indentity) within each clade (intra) of of the 2 hits (inter)
        pairs[, c(
            "inter1", # between-clade pID, representing the HTT (for hit1)
            "inter2", # same for the right-hand hit1
            "intra1", # pID of copies within the left-clade (clade A)
            "intra2"
        ) # and for the right-clade
        := data.table(
                hits[hit1, pID],
                hits[hit2, pID],
                pIDmatrix[cbind(q1, q2)],
                pIDmatrix[cbind(s1, s2)]
            )]

        # to apply criterion 1, we get the highest within clade identity
        pairs[, maxIntra := pmax(intra1, intra2)]
        cat("*") # progress indicator (this can be long)

        # and we finally apply criterion 1 to "connect" the hits
        # in effect, we return pairs of hits where the best intra-clade
        # identity is higher than at least inter-clade identity (that of hits)
        pairs[inter1 < maxIntra | inter2 < maxIntra, maxIntra, .(hit1, hit2)]
    }

    # we apply the function for batches of hit pairs and concatenate the results
    pairs <- rbindlist(lapply(hitBatches, criterion_1))

    # we now do the clustering if there are "connected hits"
    if (nrow(pairs) > 0) {
        cls <- graph_from_data_frame(pairs, directed = F)

        # we cluser into "communities" done with clauset et al. algorithm
        cls <- data.tableFromCommunities(cluster_fast_greedy(cls))

        cat("-") # to monitor progress

        # we attribute hits to "communities" named by integer numbers
        com <- integer(nrow(hits))
        com[cls$member] <- cls$community
        # so com[x] will give the community of hit "x" (which is an integer)

        # any hit that is not in a community now forms its own community
        com[com == 0L] <- 1:(sum(com == 0L)) + max(com)

        # we add the community column to the original table of htt hits
        hits[, comm := com]
    } else {
        # if there was no connection between hits, each hit gets
        # its own cummunity number corresponding to its row index
        hits[, comm := 1:.N]
    }

    # we write results to disk for safety (the function also returns the results)
    writeT(
        data = hits[, .(hit, comm, group)],
        path = stri_c("TEs/clustering/round1/", group, ".groups.txt")
    )

    hits[, .(hit, comm, group)]
}


# we apply the above function to the different groups of the super family, in parallel
res <- mclapply(
    X = groups,
    FUN = hitCommunities,
    mc.cores = nCPUs,
    mc.preschedule = F
)

res <- rbindlist(res)

# we write results to disk ---------------------------------------------------------------------
# there is one output file per job
# if the job processed several small super families, we use the super family name "other" in the output
if (length(superF) > 1) {
    superF <- "others"
}

writeT(
    data = res,
    path = stri_c("TEs/clustering/round1/", superF, ".allGroups.txt")
)

print("finished")
